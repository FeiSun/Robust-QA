<!--
 * @Author: leiyan leiyan21@mails.ucas.ac.cn
 * @Date: 2022-08-25 11:14:23
 * @LastEditors: leiyan leiyan21@mails.ucas.ac.cn
 * @LastEditTime: 2022-09-06 09:45:31
 * @FilePath: /undefined/Users/leiyan/Paper/Robust-QA/README.md
 * @Description: 这是默认设置,请设置`customMade`, 打开koroFileHeader查看配置 进行设置: https://github.com/OBKoro1/koro1FileHeader/wiki/%E9%85%8D%E7%BD%AE
-->
# Robust-QA
Robust QA: attack, defense, robust

**QA attack at inference stage**

[Adversarial Examples for Evaluating Reading Comprehension Systems](https://aclanthology.org/D17-1215.pdf)

[Reasoning Chain Based Adversarial Attack for Multi-hop Question Answering](https://arxiv.org/pdf/2112.09658.pdf)

[T3: Tree-Autoencoder Regularized Adversarial Text Generation for Targeted Attack](https://aclanthology.org/2020.emnlp-main.495.pdf)


**VQA attack at training stage**

[Dual-Key Multimodal Backdoors for Visual Question Answering](https://openaccess.thecvf.com/content/CVPR2022/papers/Walmer_Dual-Key_Multimodal_Backdoors_for_Visual_Question_Answering_CVPR_2022_paper.pdf)


**NLP attack at training stage**

[BadNL: Backdoor Attacks Against NLP Models](https://openreview.net/pdf?id=v6UimxiiR78)

[Rethinking Stealthiness of Backdoor Attack against NLP Models](https://aclanthology.org/2021.acl-long.431.pdf)

[Concealed Data Poisoning Attacks on NLP Models](https://arxiv.org/pdf/2010.12563.pdf)

[Weight Poisoning Attacks on Pre-trained Models](https://arxiv.org/pdf/2004.06660.pdf)


**CSCI 699 course**

[THIEVES ON SESAME STREET! MODEL EXTRACTION OF BERT-BASED APIS](https://arxiv.org/pdf/1910.12366.pdf)

[Imitation Attacks and Defenses for Black-box Machine Translation Systems](https://arxiv.org/pdf/2004.15015.pdf)